---
layout: post
title: 深度学习性能提升的诀窍
category: 深度学习
comments: true
---


## 提升算法性能

- 从数据上提升性能
- 从算法上提升性能
- 从算法调优上提升性能
- 从模型融合上提升性能

性能提升的力度按上表的顺序从上到下依次递减。举个例子，新的建模方法或者更多的数据带来的效果提升往往好于调出最优的参数。但这并不是绝对的，只是大多数情况下如此。 

其中有一些想法只是针对人工神经网络，但大多数想法都是通用性的。你可以将它们与其它技术结合起来使用。 

### 1、从数据上提升性能

调整训练数据或是问题的抽象定义方法可能会带来巨大的效果改善。甚至是最显著的改善。 下面是概览：
- 收集更多的数据
- 产生更多的数据
- 对数据做缩放
- 对数据做变换
- 特征选择
- 重新定义问题
#### 1）收集更多的数据

你还能收集到更多的训练数据吗？ 
你的模型的质量往往取决于你的训练数据的质量。你需要确保使用的数据是针对问题最有效的数据。 

你还希望数据尽可能多。 

深度学习和其它现代的非线性机器学习模型在大数据集上的效果更好，尤其是深度学习。这也是深度学习方法令人兴奋的主要原因之一。 

不总是数据阅读效果越好，多数情况下如此。如果让我选择，我会选择要更多的数据。

相关阅读：
[数据集压倒算法](https://www.edge.org/response-detail/26587)

#### 2) 产生更多的数据
深度学习算法往往在数据量大的时候效果好。 
我们在上一节已经提到过这一点。 
- 如果由于某些原因你得不到更多的数据，也可以制造一些数据。
- 如果你的数据是数值型的向量，那么随机生成已有向量的变形向量。
- 如果你的数据是图像，用已有的图像随机生成相似图像。
- 如果你的数据是文本，做法你懂得……

这类做法通常被称为数据扩展或是数据生成。 
你可以使用生成模型，也可以用一些简单的小技巧。 

举个例子，若是用图像数据，简单地随机选择和平移已有的图像就能取得很大的提升。它能提升模型的泛化能力，如果新的数据中包含这类变换就能得到很好的处理。 

有时候是往数据中增加噪声，这相当于是一种规则方法，避免过拟合训练数据。 

相关阅读：
[深度学习中的图像数据扩充](http://machinelearningmastery.com/image-augmentation-deep-learning-keras/)
[训练含有噪声的数据](ftp://ftp.sas.com/pub/neural/FAQ3.html#A_jitter)


#### 3) 对数据做缩放
此方法简单有效。 
使用神经网络模型的一条经验法宝就是： 
将数据缩放到激活函数的阈值范围。 
如果你使用sigmoid激活函数，将数据缩放到0~1之间。如果选用tanh激活函数，将值域控制在-1~1之间。 

输入、输出数据都经过同样的变换。比如，如果在输出层有一个sigmoid函数将输出值转换为二值数据，则将输出的y归一化为二进制。如果选用的是softmax函数，对y进行归一化还是有效的。 

我还建议你将训练数据扩展生成多个不同的版本：
- 归一化到0 ~ 1
- 归一化到-1 ~ 1
- 标准化

然后在每个数据集上测试模型的性能，选用最好的一组生成数据。 

如果更换了激活函数，最好重复做一次这个小实验。 

在模型中不适合计算大的数值。此外，还有许多其它方法来压缩模型中的数据，比如对权重和激活值做归一化，我会在后面介绍这些技巧。

 
相关阅读：

[我需要对输入数据（列向量）做标准化吗?](ftp://ftp.sas.com/pub/neural/FAQ2.html#A_std)

[如何用Scikit-Learn准备机器学习的输入数据](http://machinelearningmastery.com/prepare-data-machine-learning-python-scikit-learn/)


#### 4） 对数据做变换

与上一节的方法相关，但是需要更多的工作量。 
你必须真正了解所用到的数据。数据可视化，然后挑出异常值。 
先猜测每一列数据的分布

- 这一列数据是不是倾斜的高斯分布，若是如此，尝试用Box-Cox方法纠正倾斜
- 这一列数据是不是指数分布，若是如此，则进行对数变换
- 这一列数据是不是存在某些特性，但是难以直观地发现，尝试一下对数据平方或者开方
- 是否可以将特征离散化，以便更好地强调一些特征

凭你的直觉，尝试几种方法

- 是否可以用投影的方法对数据预处理，比如PCA？

- 是否可以将多个属性合并为单个值？

- 是否可以发掘某个新的属性，用布尔值表示？

- 是否可以在时间尺度或是其它维度上有些新发现？


神经网络有特征学习的功能，它们能够完成这些事情。 

不过你若是可以将问题的结构更好地呈现出来，网络模型学习的速度就会更快。 

在训练集上快速尝试各种变换方法，看看哪些方法有些，而哪些不起作用。 



相关阅读：

[如何定义你的机器学习问题](http://machinelearningmastery.com/how-to-define-your-machine-learning-problem/)
[特征挖掘工程，如何构造特征以及如何提升](http://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/)
[如何用Scikit-Learn准备机器学习的输入数据](http://machinelearningmastery.com/prepare-data-machine-learning-python-scikit-learn/)


#### 5） 特征选择


神经网络受不相关数据的影响很小。 
它们会对此赋予一个趋近于0的权重，几乎忽略此特征对预测值的贡献。 
你是否可以移除训练数据的某些属性呢？ 
我们有许多的特征选择方法和特征重要性方法来鉴别哪些特征可以保留，哪些特征需要移除。 
动手试一试，试一试所有的方法。 
如果你的时间充裕，我还是建议在相同的神经网络模型上选择尝试多个方法，看看它们的效果分别如何。

- 也许用更少的特征也能得到同样的、甚至更好的效果。
- 也许所有的特征选择方法都选择抛弃同一部分特征属性。那么就真应该好好审视这些无用的特征。
- 也许选出的这部分特征给你带来了新的启发，构建出更多的新特征。


相关阅读：

[特征选择入门介绍](http://machinelearningmastery.com/an-introduction-to-feature-selection/)
[基于Python的机器学习中的特征选择问题](http://machinelearningmastery.com/feature-selection-machine-learning-python/)


#### 6) 问题重构


在回到你问题的定义上来。 

你所收集到的这些观测数据是描述问题的唯一途径吗？ 

也许还有其它的途径。也许其它途径能更清晰地将问题的结构暴露出来。 

我自己非常喜欢这种练习，因为它强迫我们拓宽思路。很难做好。尤其是当你已经投入大量的时间、精力、金钱在现有的方法上。 

即使你列举了3 ~ 5种不同的方式，至少你对最后所选用的方式有充足的信心。


- 也许你可以将时间元素融入到一个窗口之中

- 也许你的分类问题可以转化为回归问题，反之亦然

- 也许可以把二值类型的输出转化为softmax的输出

- 也许你可以对子问题建模


深入思考问题是一个好习惯，最好在选择工具下手之前先完成上述步骤，以减少无效的精力投入。 

无论如何，如果你正束手无策，这个简单的连续能让你思如泉涌。 

另外，你也不必抛弃前期的大量工作，详情可以参见后面的章节。

相关阅读：

[如何定义机器学习问题](http://machinelearningmastery.com/how-to-define-your-machine-learning-problem/)
